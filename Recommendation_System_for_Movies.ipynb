{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Recommendation System for Movies.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm-Fe0gDgZlO"
      },
      "source": [
        "## Recommendation System for Movies in Pytorch using the Boltzmann Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXUr_rD8hsZx"
      },
      "source": [
        "#### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgEwstr7issP",
        "outputId": "bd620378-e6c9-47af-b8b4-9af4e934b281"
      },
      "source": [
        "!wget https://github.com/ENSP-AI-Mentoring/Restricted-Boltzmann-machine-RBM-/raw/main/dataset.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-27 18:12:59--  https://github.com/ENSP-AI-Mentoring/Restricted-Boltzmann-machine-RBM-/raw/main/dataset.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ENSP-AI-Mentoring/Restricted-Boltzmann-machine-RBM-/main/dataset.zip [following]\n",
            "--2021-11-27 18:13:00--  https://raw.githubusercontent.com/ENSP-AI-Mentoring/Restricted-Boltzmann-machine-RBM-/main/dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6583411 (6.3M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]   6.28M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-11-27 18:13:00 (94.0 MB/s) - ‘dataset.zip’ saved [6583411/6583411]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLD0NWUCi3Mv",
        "outputId": "e5096f79-0949-42a7-cc34-f8b75c73bfd1"
      },
      "source": [
        "!unzip dataset.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset.zip\n",
            "   creating: dataset/\n",
            "   creating: dataset/ml-1m/\n",
            "  inflating: dataset/ml-1m/README    \n",
            "  inflating: dataset/ml-1m/movies.dat  \n",
            "  inflating: dataset/ml-1m/ratings.dat  \n",
            "  inflating: dataset/ml-1m/users.dat  \n",
            "   creating: dataset/ml-100k/\n",
            "  inflating: dataset/ml-100k/u1.test  \n",
            "  inflating: dataset/ml-100k/u1.base  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9uX6uhgjEp2"
      },
      "source": [
        "#### Loading librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkXTYcf2gZlg"
      },
      "source": [
        "# import the Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import variable\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RQ0wz_RgZla"
      },
      "source": [
        "#### Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8_CbRzdgZlm"
      },
      "source": [
        "# import the dataset\n",
        "movies = pd.read_csv('dataset/ml-1m/movies.dat', sep='::', header = None, engine='python', encoding='latin-1')\n",
        "users = pd.read_csv('dataset/ml-1m/users.dat', sep='::', header = None, engine='python', encoding='latin-1')\n",
        "ratings = pd.read_csv('dataset/ml-1m/ratings.dat', sep='::', header = None, engine='python', encoding='latin-1')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc7N2ke7gZlo"
      },
      "source": [
        "# preparing the training set and test set\n",
        "training_set = pd.read_csv('dataset/ml-100k/u1.base', delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('dataset/ml-100k/u1.test', delimiter = '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiYRYtRVgZlp"
      },
      "source": [
        "# Getting the number of users and movies\n",
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tEm27YQgZlw"
      },
      "source": [
        "# converting the data into array with users in lines and movies in column\n",
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users+1):\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LLwqwGIgZl0"
      },
      "source": [
        "# converting the data into torch tensor\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WVDkKc_gZl4"
      },
      "source": [
        "# converting the ratings into binary rating 0 for (dislike) and 1 for (like)\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >=3 ] = 1\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >=3 ] = 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQhocz_amiT8"
      },
      "source": [
        "#### For reproductibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhqj31_8mmJI"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed  = 30\n",
        "\n",
        "def seed_value(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_value(seed)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQrDR164gZl1"
      },
      "source": [
        "#### Part 2: Building the Restricted Boltzman Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H37RvbK5gZl6"
      },
      "source": [
        "# Creating the architecture of the Neural Network\n",
        "class RBM():\n",
        "    # nv - number of visible nodes\n",
        "    # nh - number of hidden  nodes\n",
        "    # W - wigths\n",
        "    # a - bias of hidden nodes given visible nodes\n",
        "    # b - bias of visible nodes given hidden nodes\n",
        "    def __init__(self, nv, nh):\n",
        "        self.W = torch.randn(nh, nv)\n",
        "        self.a = torch.randn(1, nh)\n",
        "        self.b = torch.randn(1, nv)\n",
        "        \n",
        "    # sample the probabilites of hidden nodes given visible nodes\n",
        "    # x - visable neuron v with given probability p_h_given_v \n",
        "    # mm - product of two Torch tensors\n",
        "    # t() - transpose\n",
        "    # self.a.expand_as(wx) - we make sure that the bias are applied to each line of the minibatch\n",
        "    # p_h_given_v - probability that hidden node is activated to given visable node (that is we will find some pattern)\n",
        "    # bernoulli - our outcame is binary, a user likes a movie or not. bernoulli gives a vector wicth consits from 1s and 0s. 1 coresponds that a neuron was activated and 0 wasn't\n",
        "    # bernoulli:\n",
        "    # 1 with probability p\n",
        "    # 0 with probability 1-p\n",
        "    def sample_h(self, x):\n",
        "        wx = torch.mm(x, self.W.t())\n",
        "        activation = wx + self.a.expand_as(wx)\n",
        "        p_h_given_v = torch.sigmoid(activation)\n",
        "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "    \n",
        "    # sample the probabilites of visible nodes given hidden nodes\n",
        "    # y - visable neuron\n",
        "    def sample_v(self, y):\n",
        "        wy = torch.mm(y, self.W)\n",
        "        activation = wy + self.b.expand_as(wy)\n",
        "        p_v_given_h = torch.sigmoid(activation)\n",
        "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "    \n",
        "    # Contrastive Divergence\n",
        "    # v0 - rating of all movies of one user\n",
        "    # vk - visible nodes obtained after case samplings\n",
        "    # ph0 probabilities that  at the first iteration the hidden node = 1 with givven v0\n",
        "    # phk probabilities that  at the first iteration the hidden node = 1 with givven vk (after k-samling)\n",
        "    def train(self, v0, vk, ph0, phk):\n",
        "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "        self.b += torch.sum((v0 - vk), 0)\n",
        "        self.a += torch.sum((ph0 - phk), 0)\n",
        "\n",
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "rbm = RBM(nv, nh)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M19AM6wkgZl_"
      },
      "source": [
        "#### Part 3: Training and Testing the RBM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXN0pyAtgZmB",
        "outputId": "9318a527-cc3c-4f05-f216-4ae681330829"
      },
      "source": [
        "# Training the RBM model\n",
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    s = 0.\n",
        "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "        vk = training_set[id_user:id_user+batch_size]\n",
        "        v0 = training_set[id_user:id_user+batch_size]\n",
        "        ph0,_ = rbm.sample_h(v0)\n",
        "        \n",
        "        # loop for Contrastive Divergence\n",
        "        for k in range(10):\n",
        "            _,hk = rbm.sample_h(vk)\n",
        "            _,vk = rbm.sample_v(hk)\n",
        "            # we freeze nodes with rating = -1 \n",
        "            vk[v0<0] = v0[v0<0]\n",
        "            \n",
        "        phk,_ = rbm.sample_h(vk)\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
        "        s += 1.\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: tensor(0.3492)\n",
            "epoch: 2 loss: tensor(0.2108)\n",
            "epoch: 3 loss: tensor(0.2468)\n",
            "epoch: 4 loss: tensor(0.2468)\n",
            "epoch: 5 loss: tensor(0.2467)\n",
            "epoch: 6 loss: tensor(0.2494)\n",
            "epoch: 7 loss: tensor(0.2474)\n",
            "epoch: 8 loss: tensor(0.2476)\n",
            "epoch: 9 loss: tensor(0.2466)\n",
            "epoch: 10 loss: tensor(0.2447)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbQwGF9wgZmG",
        "outputId": "cdfdcb57-c2da-4eef-c675-0c6a5ddda815"
      },
      "source": [
        "# Testing the RBM Model\n",
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    v = training_set[id_user:id_user+1]\n",
        "    vt = test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) > 0:\n",
        "        _,h = rbm.sample_h(v)\n",
        "        _,v = rbm.sample_v(h)\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.2508)\n"
          ]
        }
      ]
    }
  ]
}